---
created: 2025-08-21 22:39:36 +0900
updated: 2025-08-24 22:16:17 +0900
title: 'AI 이미지 생성을 위한 주요 구성'
tags: ['AI']
---

- AI 이미지 생성 모델: 텍스트 프롬프트를 입력하면 이미지를 생성하는 AI
- 대표적인 서비스 또는 모델: Stable Diffusion, MidJoruney, Flux, DALL-E
- ComfyUI: 여러 이미지 생성 모델을 다룰 수 있는 UI 제공
	- Text -> Image
	- Image -> Image
	- Text -> Video
	- Image -> Video
- Diffusion Model
	- 데이터에 점점 노이즈를 추가했다가, 그 노이즈를 거꾸로 제거하면서 복원하는 과정을 학습하는 생성 모델
	- 노이즈를 추가하는 순방향 과정, 노이즈에서 원래 이미지를 복원하는 역방향 과정을 통해 학습
	- 복원하는 과정에서 프롬프트에 따라, 단순 복원 대신 프롬프트와 일치하는 새로운 이미지 생성
	- Text->Image 예시: 랜덤 노이즈 이미지로부터 AI 모델이 프롬프트에 맞는 새로운 이미지를 생성
- Latent Diffusion Model -> What does Latent mean?
	- Latent의 사전적 의미: 잠재적인
	- Latent는 원본 이미지를 압축하여 작은 벡터 공간에 표현한 것을 의미(512x512 -> 64x64)
	- LDM은 원본 이미지가 아닌 latent space에서 노이즈를 추가/제거하여 연산을 크게 절약
- VAE(Variational Autoencoder)
	- 원본 이미지를 Latent 벡터로 압축하는 인코더, Latent 벡터를 다시 이미지로 복원하는 디코더 역할
	- VAE 모델은 수백만 개의 이미지를 보면서 "어떤 정보가 중요한지", "어떻게 압축하고 복원할지" 학습
	- Text->Image 예시: Latent Space에서 점진적으로 노이즈가 제거된 표현을 디코더를 통해 고화질 이미지로 변환
- CLIP(Constrastive Language-Image Pre-training)
	- 대조 학습을 통해 텍스트와 이미지의 관계를 학습
	- 일반적인 LLM에서 사용하는 텍스트 임베딩과의 차이
		- 일반 텍스트 임베딩
			- 학습 목표: 다음 단어 예측, 문맥 이해
			- 언어적 관계에 집중
			- "사자"와 "왕"이 가까움(언어적으로 자주 함께 등장)
		- CLIP 텍스트 임베딩
			- 학습 목표: 텍스트-이미지 매칭
			- 시각적 개념과의 연결에 집중
			- "사자"와 "갈색 털"이 가까움(시각적 특징 공유)
	- 전반적인 흐름은 비슷함: 프롬프트 -> 토크나이징 -> 임베딩
	- 최종적으로 생성된 임베딩 벡터는 이미지 생성 조건으로 사용됨
- U-Net 
	- 디퓨전 모델의 핵심 신경망 아키텍처
	- 노이즈를 예측하는 네트워크
	- "어떤 노이즈를 제거해야 할지" 알려주는 역할
- 샘플러 (Sampler)
	- 노이즈 제거 알고리즘/스케줄링 방법
	- "어떤 순서와 속도로 노이즈를 제거할지" 결정
	- 디퓨전 모델 = U-Net + 샘플러 + 기타 구성요소
